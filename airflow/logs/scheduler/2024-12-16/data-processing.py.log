[2024-12-16T17:15:43.815+0000] {processor.py:186} INFO - Started process (PID=23413) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:15:43.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:15:43.820+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:43.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:15:43.833+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:15:43.958+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:43.957+0000] {override.py:1819} ERROR - Add View Menu Error: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(example_dag) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'example_dag', 'fileloc': '/opt/airflow/dags/data-processing.py', 'fileloc_hash': 32506823308002573, 'data': '{"__version": 1, "dag": {"edge_info": {}, "start_date": 1672531200.0, "_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_ ... (1396 characters truncated) ... hon", "_is_empty": false, "start_trigger_args": null, "op_args": [], "op_kwargs": {}}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', 'data_compressed': None, 'last_updated': datetime.datetime(2024, 12, 16, 17, 15, 43, 851104, tzinfo=Timezone('UTC')), 'dag_hash': 'e8da13b2133a5cc149d4ce824a3ed41f', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2024-12-16T17:15:43.964+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:43.964+0000] {override.py:1911} INFO - Created Permission View: can edit on None
[2024-12-16T17:15:43.975+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:43.975+0000] {override.py:1914} ERROR - Creation of Permission View Error: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "ab_permission_view_permission_id_view_menu_id_uq"
DETAIL:  Key (permission_id, view_menu_id)=(4, 202) already exists.

[SQL: INSERT INTO ab_permission_view (permission_id, view_menu_id) VALUES (%(permission_id)s, %(view_menu_id)s) RETURNING ab_permission_view.id]
[parameters: {'permission_id': 4, 'view_menu_id': 202}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2024-12-16T17:15:43.979+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:43.979+0000] {override.py:1819} ERROR - Add View Menu Error: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "ab_view_menu_name_uq"
DETAIL:  Key (name)=(DAG Run:example_dag) already exists.

[SQL: INSERT INTO ab_view_menu (name) VALUES (%(name)s) RETURNING ab_view_menu.id]
[parameters: {'name': 'DAG Run:example_dag'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2024-12-16T17:15:43.982+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:43.982+0000] {override.py:1911} INFO - Created Permission View: can create on None
[2024-12-16T17:15:43.988+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:43.987+0000] {override.py:1914} ERROR - Creation of Permission View Error: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "ab_permission_view_permission_id_view_menu_id_uq"
DETAIL:  Key (permission_id, view_menu_id)=(5, 203) already exists.

[SQL: INSERT INTO ab_permission_view (permission_id, view_menu_id) VALUES (%(permission_id)s, %(view_menu_id)s) RETURNING ab_permission_view.id]
[parameters: {'permission_id': 5, 'view_menu_id': 203}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2024-12-16T17:15:43.996+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:43.995+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:example_dag
[2024-12-16T17:15:44.005+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:44.005+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:example_dag
[2024-12-16T17:15:44.006+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:44.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:15:44.024+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:44.023+0000] {dag.py:3262} INFO - Creating ORM DAG for example_dag
[2024-12-16T17:15:44.037+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:44.037+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:15:44.251+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:44.247+0000] {dagbag.py:698} ERROR - Failed to write serialized DAG: /opt/airflow/dags/data-processing.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_pkey"
DETAIL:  Key (dag_id)=(example_dag) already exists.

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: {'dag_id': 'example_dag', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_parsed_time': datetime.datetime(2024, 12, 16, 17, 15, 44, 36410, tzinfo=Timezone('UTC')), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/data-processing.py', 'processor_subdir': '/opt/airflow/dags', 'owners': 'airflow', 'dag_display_name': None, 'description': 'An example DAG', 'default_view': 'grid', 'schedule_interval': '{"type": "timedelta", "attrs": {"days": 1, "seconds": 0, "microseconds": 0}}', 'timetable_description': '', 'dataset_expression': 'null', 'max_active_tasks': 16, 'max_active_runs': 16, 'max_consecutive_failed_dag_runs': 0, 'has_task_concurrency_limits': False, 'has_import_errors': False, 'next_dagrun': DateTime(2024, 12, 15, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_start': DateTime(2024, 12, 15, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_end': DateTime(2024, 12, 16, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_create_after': DateTime(2024, 12, 16, 0, 0, 0, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-12-16T17:15:44.252+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:15:44.252+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:15:44.254+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_pkey"
DETAIL:  Key (dag_id)=(example_dag) already exists.

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: {'dag_id': 'example_dag', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_parsed_time': datetime.datetime(2024, 12, 16, 17, 15, 44, 36410, tzinfo=Timezone('UTC')), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/data-processing.py', 'processor_subdir': '/opt/airflow/dags', 'owners': 'airflow', 'dag_display_name': None, 'description': 'An example DAG', 'default_view': 'grid', 'schedule_interval': '{"type": "timedelta", "attrs": {"days": 1, "seconds": 0, "microseconds": 0}}', 'timetable_description': '', 'dataset_expression': 'null', 'max_active_tasks': 16, 'max_active_runs': 16, 'max_consecutive_failed_dag_runs': 0, 'has_task_concurrency_limits': False, 'has_import_errors': False, 'next_dagrun': DateTime(2024, 12, 15, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_start': DateTime(2024, 12, 15, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_end': DateTime(2024, 12, 16, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_create_after': DateTime(2024, 12, 16, 0, 0, 0, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2024-12-16T17:16:14.365+0000] {processor.py:186} INFO - Started process (PID=23482) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:16:14.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:16:14.370+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:16:14.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:16:14.381+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:16:14.549+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:16:14.549+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:16:14.578+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:16:14.578+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:16:14.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.243 seconds
[2024-12-16T17:16:45.066+0000] {processor.py:186} INFO - Started process (PID=23546) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:16:45.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:16:45.071+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:16:45.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:16:45.080+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:16:45.104+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:16:45.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:16:45.132+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:16:45.132+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:16:45.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.091 seconds
[2024-12-16T17:17:15.198+0000] {processor.py:186} INFO - Started process (PID=23610) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:17:15.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:17:15.201+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:17:15.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:17:15.210+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:17:15.348+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:17:15.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:17:15.373+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:17:15.373+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:17:15.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.199 seconds
[2024-12-16T17:17:45.460+0000] {processor.py:186} INFO - Started process (PID=23654) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:17:45.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:17:45.465+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:17:45.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:17:45.479+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:17:45.510+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:17:45.509+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:17:45.548+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:17:45.548+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:17:45.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.126 seconds
[2024-12-16T17:18:16.732+0000] {processor.py:186} INFO - Started process (PID=23719) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:18:16.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:18:16.735+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:18:16.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:18:16.744+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:18:16.761+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:18:16.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:18:16.797+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:18:16.797+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:18:16.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.093 seconds
[2024-12-16T17:18:46.959+0000] {processor.py:186} INFO - Started process (PID=23775) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:18:46.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:18:46.963+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:18:46.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:18:46.973+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:18:47.149+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:18:47.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:18:47.182+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:18:47.182+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:18:47.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.259 seconds
[2024-12-16T17:19:17.392+0000] {processor.py:186} INFO - Started process (PID=23830) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:19:17.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:19:17.395+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:19:17.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:19:17.404+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:19:17.425+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:19:17.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:19:17.455+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:19:17.455+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:19:17.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.097 seconds
[2024-12-16T17:19:47.664+0000] {processor.py:186} INFO - Started process (PID=23889) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:19:47.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:19:47.668+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:19:47.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:19:47.676+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:19:47.693+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:19:47.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:19:47.725+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:19:47.725+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:19:47.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.087 seconds
[2024-12-16T17:20:18.149+0000] {processor.py:186} INFO - Started process (PID=23953) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:20:18.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:20:18.155+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:20:18.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:20:18.167+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:20:18.340+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:20:18.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:20:18.369+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:20:18.369+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:20:18.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.256 seconds
[2024-12-16T17:20:48.834+0000] {processor.py:186} INFO - Started process (PID=24018) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:20:48.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:20:48.840+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:20:48.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:20:48.854+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:20:48.893+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:20:48.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:20:48.949+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:20:48.949+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:20:48.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.150 seconds
[2024-12-16T17:21:19.090+0000] {processor.py:186} INFO - Started process (PID=24083) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:21:19.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:21:19.102+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:21:19.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:21:19.123+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:21:19.142+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:21:19.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:21:19.183+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:21:19.182+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:21:19.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.151 seconds
[2024-12-16T17:21:49.508+0000] {processor.py:186} INFO - Started process (PID=24148) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:21:49.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:21:49.517+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:21:49.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:21:49.526+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:21:49.672+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:21:49.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:21:49.698+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:21:49.697+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:21:49.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.221 seconds
[2024-12-16T17:22:20.199+0000] {processor.py:186} INFO - Started process (PID=24213) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:22:20.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:22:20.204+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:22:20.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:22:20.214+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:22:20.234+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:22:20.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:22:20.264+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:22:20.264+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:22:20.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.096 seconds
[2024-12-16T17:22:50.478+0000] {processor.py:186} INFO - Started process (PID=24278) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:22:50.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:22:50.490+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:22:50.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:22:50.513+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:22:50.533+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:22:50.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:22:50.570+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:22:50.570+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:22:50.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.134 seconds
[2024-12-16T17:23:21.419+0000] {processor.py:186} INFO - Started process (PID=24343) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:23:21.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:23:21.430+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:23:21.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:23:21.447+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:23:21.602+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:23:21.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:23:21.638+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:23:21.638+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:23:21.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.270 seconds
[2024-12-16T17:23:51.777+0000] {processor.py:186} INFO - Started process (PID=24409) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:23:51.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:23:51.781+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:23:51.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:23:51.793+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:23:51.819+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:23:51.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:23:51.857+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:23:51.856+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:23:51.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.117 seconds
[2024-12-16T17:24:21.957+0000] {processor.py:186} INFO - Started process (PID=24473) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:24:21.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:24:21.961+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:24:21.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:24:21.973+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:24:21.985+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:24:21.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:24:22.019+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:24:22.019+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:24:22.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.090 seconds
[2024-12-16T17:24:52.472+0000] {processor.py:186} INFO - Started process (PID=24538) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:24:52.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:24:52.479+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:24:52.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:24:52.494+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:24:52.693+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:24:52.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:24:52.723+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:24:52.723+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:24:52.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.286 seconds
[2024-12-16T17:25:22.809+0000] {processor.py:186} INFO - Started process (PID=24603) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:25:22.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:25:22.815+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:25:22.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:25:22.834+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:25:22.876+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:25:22.875+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:25:22.909+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:25:22.909+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:25:22.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.134 seconds
[2024-12-16T17:25:52.999+0000] {processor.py:186} INFO - Started process (PID=24668) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:25:53.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:25:53.005+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:25:53.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:25:53.015+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:25:53.030+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:25:53.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:25:53.065+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:25:53.065+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:25:53.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.098 seconds
[2024-12-16T17:26:23.307+0000] {processor.py:186} INFO - Started process (PID=24733) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:26:23.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:26:23.316+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:26:23.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:26:23.334+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:26:23.466+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:26:23.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:26:23.491+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:26:23.491+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:26:23.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.242 seconds
[2024-12-16T17:26:53.588+0000] {processor.py:186} INFO - Started process (PID=24799) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:26:53.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:26:53.593+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:26:53.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:26:53.607+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:26:53.637+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:26:53.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:26:53.680+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:26:53.679+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:26:53.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.126 seconds
[2024-12-16T17:27:24.066+0000] {processor.py:186} INFO - Started process (PID=24863) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:27:24.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:27:24.079+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:27:24.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:27:24.099+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:27:24.122+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:27:24.122+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:27:24.158+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:27:24.157+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:27:24.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.131 seconds
[2024-12-16T17:27:54.701+0000] {processor.py:186} INFO - Started process (PID=24928) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:27:54.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:27:54.704+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:27:54.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:27:54.716+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:27:54.877+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:27:54.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:27:54.906+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:27:54.906+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:27:54.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.233 seconds
[2024-12-16T17:28:25.577+0000] {processor.py:186} INFO - Started process (PID=24993) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:28:25.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:28:25.581+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:28:25.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:28:25.592+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:28:25.616+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:28:25.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:28:25.644+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:28:25.644+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:28:25.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.103 seconds
[2024-12-16T17:28:56.625+0000] {processor.py:186} INFO - Started process (PID=25058) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:28:56.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:28:56.629+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:28:56.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:28:56.638+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:28:56.650+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:28:56.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:28:56.680+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:28:56.680+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:28:56.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.087 seconds
[2024-12-16T17:29:26.904+0000] {processor.py:186} INFO - Started process (PID=25120) to work on /opt/airflow/dags/data-processing.py
[2024-12-16T17:29:26.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/data-processing.py for tasks to queue
[2024-12-16T17:29:26.910+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:29:26.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/data-processing.py
[2024-12-16T17:29:26.923+0000] {processor.py:925} INFO - DAG(s) 'example_dag' retrieved from /opt/airflow/dags/data-processing.py
[2024-12-16T17:29:27.068+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:29:27.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-16T17:29:27.091+0000] {logging_mixin.py:190} INFO - [2024-12-16T17:29:27.091+0000] {dag.py:4180} INFO - Setting next_dagrun for example_dag to 2024-12-15 00:00:00+00:00, run_after=2024-12-16 00:00:00+00:00
[2024-12-16T17:29:27.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/data-processing.py took 0.233 seconds
